---
title: "Normalization of ChIP-seq experiments using Background Read Density"
author: '[Benjamin Leblanc](https://github.com/benja0x40)'
date: "`r format(Sys.time(), '%d.%m.%Y')`"
vignette: >
  %\VignetteIndexEntry{ChIP-seq normalization using BRD}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
fontsize: 11pt
output:
  html_document:
    number_sections: true
    toc: true
    toc_depth: 2
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 2
---

```{r hidden_dependencies, include=FALSE}
library(knitr)
suppressPackageStartupMessages(library(Tightrope))
```

___

The purpose of this documentation is to provide a practical guide to the use of
`R` functions available in `Tightrope`. A basic knowledge of the `R` syntax
and data structures, and of [Bioconductor](http://www.bioconductor.org/)
objects used to represent and manipulate mapped reads and genomic intervals
will help to understand and adapt the included source code examples to other
ChIP-seq datasets.

___

\newpage

# Introduction

`Tightrope` is an `R` package proposing a ChIP-seq normalization method, named
Background Read Density (BRD)^[1,2](#R1)^, capable of accurate estimation
of normalization factors in conditions involving global variations of chromatin
marks.

Basic sequencing depth correction can be dramatically misleading in such
experimental conditions, and since these experiments have become important 
for research on chromatin regulation and in specific cancer studies, accurate
ChIP-seq normalization methods are increasingly needed.

In the recent years, several spike-in protocols^[3-6](#R3)^ were introduced to
circumvent ChIP-seq normalization issues with an accessible experimental
strategy. Seeking an alternative due to reliability concerns with our own
spike-in attempts, we used an empirical computational approach to design
the BRD method while we were studying H3K27me3 profiles in a cellular model
of Diffuse Intrinsic Pontine Glioma (DIPG)^[1](#R1)^.

After initial validation and application of the BRD normalization to these
H3K27me3 ChIP-seq experiments, we used original data and published datasets to
significantly improve the versatility and reliability of our method.
As illustrated by the examples included in this document, with different
experimental setups and chromatin marks this improved BRD method leads to
normalizations that are rather equivalent to spike-in-based normalizations or
which are the most consistent ones in cases where both methods differ
noticeably.

Following these developments, we are now preparing a manuscript describing
the BRD method and reporting our comparative analyses between spike-in and
BRD normalizations for the most representative datasets^[2](#R2)^.

## Principle and prerequisites

The BRD normalization aims to rescale read counts or genomic coverage values
from different ChIP-seq experiments, such that background levels - which should
correspond mainly to ChIP-seq reads from non-specific DNA fragments - become
equalized between the experimental conditions.

To achieve this goal the BRD method is designed upon the following assumptions
and prerequisites.

  a. For all considered experimental conditions, some portions of the genome are
     invariably devoid of the immuno-precipitated chromatin mark.
   
     We use the term **background candidates** to designate such invariable
     genomic regions in a given experimental setup.
   
  b. Background candidates can be distinguished as a specific density mode in
     appropriately transformed ChIP-seq read count distributions.

A first prerequisite when applying the BRD method is to define the portions of
the genome that are biologically relevant for the search of background
candidates.

Although a completely naive search of background candidates among the whole
genome should be possible in theory, without further assumptions this search
may not lead to the selection of valid candidates.
For instance, some chromatin marks can cover most of the genome at low but
distinguishable levels, as it can be observed with H3K27me3 ChIP-seq profiles
in populations of Embryonic Stem Cells (ESCs) or Neural Stem Cells (NSCs).
In such situation the second assumption (**b.** above) of the BRD method does
not hold since the density mode of background candidates can be masked
by a close and more prevalent mode corresponding to minimal but extensive
ChIP enrichments.

For commonly studied marks that are linked with the regulation of gene
expression, a reasonable option consist in searching background candidates
over gene units or transcription start sites (TSS), assuming
that the mark of interest would be always absent at a subpopulation
of genes, for instance the constitutively expressed ones or silent ones in the
considered experimental conditions. 

The second prerequisite is that the ChIP-seq dataset must include background
profiles (e.g. input DNA, ChIP-seq performed with IgG or in KO conditions),
preferably generated using the same sequencing setup as for the ChIP profiles.
For technical reasons, 2 background profiles is the minimum for the current
version of `Tightrope`.

## Technical overview

The figure below illustrates a ChIP-seq normalization workflow with the current
version of `Tightrope`, giving an overview of algorithms implemented in its
core functions (**A**), as well as examples of resulting control graphs
(**B,C**) which provide guidance for the choice of parameters required by these
functions.

```{r overview, echo=FALSE, out.width="80%", fig.align='center'}
include_graphics("../images/Overview.png")
```

As shown in this workflow, the BRD method consists mainly in the transformation
of read counts over chosen genomic regions (**A**) into a bivariate density 
distribution (**B**), a technique that we name Count Density after Dithering
and Dimensionality Reduction (CDaDaDR) which combines a principal component
analysis and a non-parametric density estimation, followed by the identification
of the local density mode which corresponds to the best background candidates
(**C**) thanks to a clustering technique based on density gradients.

## User interventions

Overall, using the BRD method involves two key interventions. As explained in
the previous section, the first one consists in choosing genomic regions that
are relevant for the search of background candidates and generating the
corresponding read count matrix.

The second intervention consists in tuning the most influencial parameters of
the `BRD` function, which are the number of distinct density modes
(i.e. clusters) and the density threshold values used to define these clusters.
Practically, the default threshold values should perform reasonably well for
common use cases and the remaining decisions after generating read count
matrixes will often be limited to a choice between 1 or 2 clusters.
This choice should be made after observing the bivariate density distribution
generated by the `PlotBRD` function, opting for a value of 1 or 2 clusters
for a globally unimodal or bimodal density respectively.

\newpage

# Installations

The following softwares must be installed before `Tightrope` can be used.

  - [R environment](https://www.r-project.org/) version 3.4 or newer.
  - To develop and execute `R` scripts we recommend using [RStudio](https://www.rstudio.com/products/rstudio/download).
  - CRAN packages `devtools`, `stringr`, `data.table`, `triangle`, `caTools`, `ica`, `FNN`, `igraph`, `mixtools`.
  - [Bioconductor](http://www.bioconductor.org/) packages `Rsamtools`, `GenomicAlignments`, `GenomicRanges`, `GenomicFeatures`, `rtracklayer`, `biomaRt`.
  - GitHub package [Barbouille](https://github.com/benja0x40/Barbouille).

The next subsections provide further indications for these installations.

## R and RStudio environments

If `R` and RStudio are not already installed.
  
  * Manually download and install [R](https://cloud.r-project.org).
    
  * Manually download and install [RStudio](https://www.rstudio.com/products/rstudio/download).

## R package dependencies

Once `R` and RStudio are installed, open RStudio and run the `R` code below
which should install all required packages automatically. While `R` will perfom
these tasks, you may be prompted for a confirmation of package installations
or updates.

```R
# Setting value below to TRUE will reinstall all required packages (optional)
reinstall <- FALSE

# Detect already installed packages
pkg <- ifelse(reinstall, c(), installed.packages()[, "Package"])

# CRAN packages
lst <- c(
  "devtools", "stringr", "data.table", "triangle", "caTools", "ica", "FNN",
  "igraph", "mixtools"
)
lst <- setdiff(lst, pkg)
if(length(lst) > 0) install.packages(lst, dependencies = T)

# Bioconductor packages
source("https://bioconductor.org/biocLite.R")
lst <- c(
  "Rsamtools", "GenomicAlignments", "GenomicRanges", "GenomicFeatures",
  "rtracklayer", "biomaRt"
)
lst <- setdiff(lst, pkg)
if(length(lst) > 0) biocLite(lst)

# GitHub packages
library("devtools")
install_github("benja0x40/Barbouille", dependencies = T)
```

## Tightrope

Install `Tightrope` using RStudio as follows:

  * Open menu `Tools > Install Packages...`

  * Select `Install from: Package Archive File (.tgz; .tar.gz)`
  
  * Browse your computer to select the package archive file (e.g. `Tightrope_0.6.0.tar.gz`)
  
  * Click `Install`

Once `Tightrope` is installed, the first thing to do when starting a work
session is to load the package into the active `R` session.

```{r}
 # Load Tightrope package (this will produce numerous messages)
library(Tightrope)
```

At this stage, it is possible to obtain the list of `R` functions available
in `Tightrope` and to browse the builtin documentation by calling the `help()`
function in the `R` console.

```{r eval=FALSE}
help(package = "Tightrope")
```

And the present document can be shown by using the `vignette()` function.

```{r eval=FALSE}
vignette("BRD", package = "Tightrope")
```

\newpage

# Standard workflow

## Genomic regions

To simplify the generation of read count matrixes, `Tightrope` provides genomic
regions in human and mouse which correspond to annotated gene features from
the Ensembl database, as well as CpG-islands from UCSC and blacklisted regions
from the ENCODE project.

```{r}
# Human genome annotations (Ensembl GRCh38.p10 release 91)
data("EGA91_human")    # Gene features from Ensembl
data("CGI_hg38")       # CpG Islands from UCSC
data("hg38_blacklist") # Blacklisted regions from ENCODE
```

```{r}
# Mouse genome annotations (Ensembl GRCm38.p5 release 91)
data("EGA91_mouse")    # Gene features from Ensembl
data("CGI_mm10")       # CpG Islands from UCSC
data("mm10_blacklist") # Blacklisted regions from ENCODE
```

The `summary` element in `EGA91_human` and `EGA91_mouse` objects contains a
brief description of provided gene features.

```{r eval=FALSE}
EGA91_human$summary # Summary of gene features in Human
```

```{r show_dataset, echo=FALSE}
kable(EGA91_human$summary)
```

For instance, gene units in human according to Ensembl GRCh38.p10 release 91 are
provided by the `GRanges` object `EGA91_human$GNU`.

```{r echo=FALSE}
# Simplify EGA91_human$GNU for cleaner/concise output in the pdf vignette
grg <- EGA91_human$GNU
mcols(grg) <- mcols(grg)[, 3, drop = F]
grg
suppressWarnings(rm(grg))
```

## Read count matrixes

The function `ReadCountMatrix` can generate read counts over genomic intervals
for multiple bam files. First, let's consider a virtual dataset in mouse
with 4 experimental conditions.

```{r eval=FALSE}
# Paths to bam files (mapped reads of the ChIP-seq dataset)
bam.files <- c(
  "~/sequencing/sample1.bam",
  "~/sequencing/sample2.bam",
  "~/sequencing/sample3.bam",
  "~/sequencing/sample4.bam",
)
```

```{r eval=FALSE}
# Names of experimental conditions (ordered consistently with bam.files)
conditions <- c(
  "H3K27me3_WT",
  "H3K27me3_K27M",
  "Input_WT", 
  "Input_K27M"
)
```

Assuming that this virtual ChIP-seq dataset was generated by single-end
sequencing and that the reads were mapped on the GRCm38 (UCSC mm10)
genome build, a matrix of read counts over genes could be generated as follows.

```{r eval=FALSE}
# Read counts over genes (single-end)
cnt <- ReadCountMatrix(
  bam.files, EGA91_mouse$GNU, paired = F, names = conditions,
  param = ScanBamParam(
    flag = scanBamFlag(isDuplicate = F, isUnmappedQuery = F)
  )
)
```

Similarly if the dataset was generated by paired-end sequencing, 
a matrix of read counts over genes would be generated as follows.

```{r eval=FALSE}
# Read counts over genes (paired-end)
cnt <- ReadCountMatrix(
  bam.files, EGA91_mouse$GNU, paired = T, names = conditions,
  param = ScanBamParam(
    flag = scanBamFlag(isDuplicate = F, isUnmappedQuery = F, isProperPair = T)
  )
)
```

Instead of using whole genes to search for background candidates, a matrix
of read counts over promoters could for instance be generated thanks to
provided genomic features.

```{r eval=FALSE}
# Define mouse promoter regions as 4kb windows centered at each TSS
TSS <- resize(EGA91_mouse$TSS, width = 4000, fix = "center", use.names = F)

# Read counts over promoters (single-end)
cnt <- ReadCountMatrix(
  bam.files, TSS, paired = F, names = conditions,
  param = ScanBamParam(flag = scanBamFlag(isDuplicate = F, isUnmappedQuery = F))
)
```

## Adjustment of parameters

Once the read count matrix aimed for the search of background candidates has
been generated, a preliminary application of the BRD method takes the following
form.

```{r eval=FALSE}
# Define column identifiers corresponding to Input profiles
ctrl <- c("Input_WT", "Input_K27M")

# Preliminary application of the BRD method based on the read count matrix cnt
brd <- BRD(cnt, controls = ctrl)
```

After this, calling the `PlotBRD` function will generate control graphs that
are necessary to adjust key parameters of the `BRD` function, that is
the number of clusters `ncl` and the density thresholds `bdt`.

```{r eval=FALSE}
PlotBRD(brd) # Generate BRD control graphs (e.g. bivariate density distribution)
```

For instance, with a bivariate density distribution similar to the one shown in
section [1.2](#1.2), the number of clusters must be set to 2 for an accurate
estimation of normalization factors.

```{r eval=FALSE}
# Adjusted application of the BRD method for a bimodal bivariate density  
brd <- BRD(cnt, controls = ctrl, ncl = 2)
```

In this virtual example, the estimated normalization factor for each
experimental condition would be given by the object `brd$normfactors`.

Applying the BRD normalization to log2 transformed read counts or coverage
vectors simply consist in adding these factors.
Thus, the raw read counts should be normalized as follows.

```{r eval=FALSE}
# Apply BRD normalization factors to raw read counts
nrm <- t(t(cnt) * 2^brd$normfactors)
```

More detailed examples of normalization with real ChIP-seq datasets can be
found in the next section.

## Normalization

## Verifications

# Getting help

## Documentation and examples

## Frequently asked questions

  * If I have replicates, should I normalize them separately or all together?

  * I would like to load and use my own annotation object, how should I do?
  
  * Why estimated scaling factors differ slightly whether `ncl` is unspecified or manually set to `1`?

\newpage

# Acknowledgements

Thanks to Itys Comet, Daria Shlyueva, Aliaksandra Radzisheuskaya,
Sachin Pundhir and Albin Sandelin for their comments and suggestions
during the development of the BRD method,
and to Jens Vilstrup Johansen and Sudeep Sahadevan
from the bioinformatics core facility at the
[Biotech Research and Innovation Centre](http://www.bric.ku.dk)
for their support.

# References

<a name="R1"></a>1. Mohammad et al. 2017 - *EZH2 is a potential therapeutic target for H3K27M-mutant pediatric gliomas.*  
[publisher](https://dx.doi.org/10.1038/nm.4293) | [pubmed](https://www.ncbi.nlm.nih.gov/pubmed/28263309)

<a name="R2"></a>2. Leblanc B., Mohammad F., Hojfeldt J., Helin K. - *Normalization of ChIP-seq experiments involving global variations of chromatin marks.*  
(in preparation)

<a name="R3"></a>3. Bonhoure et al. 2014 - *Quantifying ChIP-seq data: a spiking method providing an internal reference for sample-to-sample normalization*  
[publisher](https://dx.doi.org/10.1101/gr.168260.113) | [pubmed](https://www.ncbi.nlm.nih.gov/pubmed/24709819)

<a name="R4"></a>4. Orlando et al. 2014 - *Quantitative ChIP-Seq normalization reveals global modulation of the epigenome.*  
[publisher](https://dx.doi.org/10.1016/j.celrep.2014.10.018) | [pubmed](https://www.ncbi.nlm.nih.gov/pubmed/25437568)

<a name="R5"></a>5. Hu et al. 2015 - *Biological chromodynamics: a general method for measuring protein occupancy across the genome by calibrating ChIP-seq.*  
[publisher](https://dx.doi.org/10.1093/nar/gkv670) | [pubmed](https://www.ncbi.nlm.nih.gov/pubmed/26130708)

<a name="R6"></a>6. Egan et al. 2016 - *An Alternative Approach to ChIP-Seq Normalization Enables Detection of Genome-Wide Changes in Histone H3 Lysine 27 Trimethylation upon EZH2 Inhibition.*  
[publisher](https://dx.doi.org/10.1371/journal.pone.0166438) | [pubmed](https://www.ncbi.nlm.nih.gov/pubmed/27875550)
